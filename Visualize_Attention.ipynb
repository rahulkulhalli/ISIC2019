{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from discriminator import Discriminator\n",
    "from generator import Generator\n",
    "from trainer import Trainer\n",
    "from config import Config\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set yo seed.\n",
    "SEED = 42069\n",
    "\n",
    "# Set NumPy seed.\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set PyTorch seed.\n",
    "torch.manual_seed(SEED)\n",
    "cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a config object.\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(z_dim=config.z_dim, num_classes=config.num_classes, \n",
    "                      base_width=config.base_width, \n",
    "                      base_filters=config.base_filters, \n",
    "                      use_attention=config.use_attention)\n",
    "    \n",
    "if config.pretrained:\n",
    "    generator.load_state_dict(torch.load(config.checkpoint_path \n",
    "                                         + 'models/generator_{}.pth'\n",
    "                                         .format(1499)))\n",
    "    \n",
    "generator = generator.to(config.device)\n",
    "    \n",
    "discriminator = Discriminator(config.num_classes, \n",
    "                              base_filters=config.base_filters, \n",
    "                              use_attention=config.use_attention, \n",
    "                              use_dropout=config.use_dropout)\n",
    "\n",
    "if config.pretrained:\n",
    "    discriminator.load_state_dict(torch.load(config.checkpoint_path \n",
    "                                         + 'models/discriminator_{}.pth'\n",
    "                                         .format(1499)))\n",
    "\n",
    "discriminator = discriminator.to(config.device)\n",
    "\n",
    "if config.data_parallel:\n",
    "    generator = nn.DataParallel(generator)\n",
    "    discriminator = nn.DataParallel(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataloaders.\n",
    "train_dataloader, test_dataloader = utils.get_dataloaders(config.train_root,\n",
    "                                                          config.test_root,\n",
    "                                                          batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration, (X, y) in enumerate(test_dataloader):\n",
    "                \n",
    "    batch_size = int(X.size()[0])\n",
    "\n",
    "    # Real\n",
    "    X = torch.FloatTensor(X).to(config.device)\n",
    "    y = torch.LongTensor(y).to(config.device)\n",
    "    \n",
    "    real_score, attn_map = discriminator(X, y, visualize=True)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map.size() # B X (64x64) X (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_img(img_tensor):\n",
    "    \n",
    "    img = img_tensor.cpu().numpy()\n",
    "    \n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "    img = np.clip((img * 0.5) + 0.5, 0., 1.)\n",
    "    \n",
    "    return (img * 255.).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    \n",
    "    image = deprocess_img(fake_X[i, :, :, :])\n",
    "    \n",
    "    attention = attn_map.detach().cpu()[i, :, :]\n",
    "    \n",
    "    attention = attention.view(64, 64, 32, 32).numpy()\n",
    "    \n",
    "    query_locations = [[16, 16], [32, 32], [50, 50]]\n",
    "    \n",
    "    f = plt.figure(figsize=(10, 10))\n",
    "    for j, location in enumerate(query_locations):\n",
    "        amap = attention[location[0], location[1], :, :]\n",
    "        amap_i = Image.fromarray(amap).resize((256, 256))\n",
    "        amap = np.array(amap_i)\n",
    "        \n",
    "        amap_i.close()\n",
    "        \n",
    "        plt.subplot(1, 3, j+1)\n",
    "        plt.imshow(image)\n",
    "        plt.imshow(amap, interpolation=\"bicubic\", cmap='gray', alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    \n",
    "    image = deprocess_img(X[i, :, :, :])\n",
    "    \n",
    "    attention = attn_map.detach().cpu()[i, :, :]\n",
    "    \n",
    "    attention = attention.view(64, 64, 32, 32).numpy()\n",
    "    \n",
    "    query_locations = [[16, 16], [32, 32], [50, 50]]\n",
    "    \n",
    "    f = plt.figure(figsize=(10, 10))\n",
    "    for j, location in enumerate(query_locations):\n",
    "        amap = attention[location[0], location[1], :, :]\n",
    "        amap_i = Image.fromarray(amap).resize((256, 256))\n",
    "        amap = np.array(amap_i)\n",
    "        \n",
    "        amap_i.close()\n",
    "        \n",
    "        plt.subplot(1, 3, j+1)\n",
    "        plt.imshow(image)\n",
    "        plt.imshow(amap, interpolation=\"bicubic\", cmap='gray', alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {idx: cls for cls, idx in test_dataloader.dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    \n",
    "    image = deprocess_img(X[i, :, :, :])\n",
    "    \n",
    "    attention = attn_map.detach().cpu()[i, :, :]\n",
    "    \n",
    "    attention = attention.view(64, 64, 32, 32).numpy()\n",
    "    \n",
    "    query_locations = [[16, 16], [32, 32], [50, 50]]\n",
    "    \n",
    "    print(idx_to_class[int(y[i].cpu().numpy())])\n",
    "    f = plt.figure(figsize=(10, 10))\n",
    "    for j, location in enumerate(query_locations):\n",
    "        amap = attention[location[0], location[1], :, :]\n",
    "        amap_i = Image.fromarray(amap).resize((256, 256))\n",
    "        amap = np.array(amap_i)\n",
    "        \n",
    "        amap_i.close()\n",
    "        \n",
    "        plt.subplot(1, 3, j+1)\n",
    "        plt.imshow(image)\n",
    "        plt.imshow(amap, interpolation=\"bicubic\", cmap='Greens', alpha=0.6)\n",
    "        plt.scatter(location[1]*4, location[0]*4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Number of GPUs to train on.\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1, 2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from discriminator import Discriminator\n",
    "from generator import Generator\n",
    "from trainer import Trainer\n",
    "from config import Config\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set yo seed.\n",
    "SEED = 42069\n",
    "\n",
    "# Set NumPy seed.\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set PyTorch seed.\n",
    "torch.manual_seed(SEED)\n",
    "cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a config object.\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Generator and Discriminator into memory and push them onto the GPU(s) if told. \n",
    "# If the config flag contains a positive non-zero starting epoch, it will load the models\n",
    "# checkpointed at that (epoch - 1) [epochs start from 0].\n",
    "\n",
    "generator = Generator(z_dim=config.z_dim, num_classes=config.num_classes, \n",
    "                      base_width=config.base_width, \n",
    "                      base_filters=config.base_filters, \n",
    "                      use_attention=config.use_attention)\n",
    "    \n",
    "if config.pretrained:\n",
    "    generator.load_state_dict(torch.load(config.checkpoint_path \n",
    "                                         + 'models/generator_{}.pth'\n",
    "                                         .format(config.start_epoch - 1)))\n",
    "    \n",
    "generator = generator.to(config.device)\n",
    "    \n",
    "discriminator = Discriminator(config.num_classes, \n",
    "                              base_filters=config.base_filters, \n",
    "                              use_attention=config.use_attention, \n",
    "                              use_dropout=config.use_dropout)\n",
    "\n",
    "if config.pretrained:\n",
    "    discriminator.load_state_dict(torch.load(config.checkpoint_path \n",
    "                                         + 'models/discriminator_{}.pth'\n",
    "                                         .format(config.start_epoch - 1)))\n",
    "\n",
    "discriminator = discriminator.to(config.device)\n",
    "\n",
    "if config.data_parallel:\n",
    "    generator = nn.DataParallel(generator)\n",
    "    discriminator = nn.DataParallel(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataloaders.\n",
    "train_dataloader, test_dataloader = utils.get_dataloaders(config.train_root,\n",
    "                                                          config.test_root,\n",
    "                                                          batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer object.\n",
    "trainer = Trainer(config, train_dataloader, generator=generator, discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Commence the training.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle this depending on whether the training was stopped or whether it naturally finished.\n",
    "ABORTED = True\n",
    "\n",
    "if ABORTED:\n",
    "    # Haxx. This is a workaround to prevent the method from using the current epoch in the file names.\n",
    "    trainer.current_epoch -= 1\n",
    "\n",
    "# Dump the metrics to pickle files.\n",
    "trainer.dump_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate, save, and display the loss plots.\n",
    "utils.plot_losses(\n",
    "    'losses.png',\n",
    "    g_loss=trainer.g_loss,\n",
    "    d_loss=trainer.d_loss,\n",
    "    superimpose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GIF of the samples.\n",
    "# TODO: GIFs take too much space. Maybe ffmpeg to movie and convert to gif of low quality?\n",
    "utils.create_interpolation(filename=config.checkpoint_path + 'interpolation.gif',\n",
    "                           im_path=config.checkpoint_path + 'samples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
